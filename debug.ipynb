{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mistsink/.local/share/virtualenvs/ULTRA-KJLySXkB/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/mistsink/.local/share/virtualenvs/ULTRA-KJLySXkB/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import transformers\n",
    "from transformers import Trainer, TrainingArguments, HfArgumentParser\n",
    "\n",
    "from script.build_model import build_model, build_tokenizer_model, build_tokenizer\n",
    "from src.trainer.metric import ROUGE, metric_fn\n",
    "from src.trainer.trainer import KGLLMTrainer\n",
    "from config.config import Config\n",
    "from src.data.datasets import FB15k237Inductive\n",
    "from src.data.types import CustomData\n",
    "from src.ultra import tasks, util\n",
    "from src.ultra.models import Ultra\n",
    "\n",
    "\n",
    "def parse_args(config_path: str) -> Config:\n",
    "    parser = HfArgumentParser(Config)\n",
    "    cfg: Config = parser.parse_yaml_file(config_path)[0]\n",
    "    cfg.train = cfg.train.set_dataloader(train_batch_size=cfg.train.batch_size, eval_batch_size=cfg.train.batch_size)\n",
    "\n",
    "    # get_logger().\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def get_data(cfg: Config) -> tuple[InMemoryDataset, CustomData, CustomData, CustomData]:\n",
    "    dataset = util.build_dataset(cfg)\n",
    "    return dataset, dataset[0], dataset[1], dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data.special_tokens import SpecialToken\n",
    "\n",
    "\n",
    "cfg = parse_args(\"config/pretrain/pretrain_0.yaml\")\n",
    "transformers.set_seed(cfg.train.seed)\n",
    "\n",
    "task_name = cfg.task.name\n",
    "\n",
    "# data sampler, loader, collator -> custom trainer\n",
    "dataset, train_data, valid_data, test_data = get_data(cfg=cfg)\n",
    "\n",
    "# tokenizer, model = build_tokenizer_model(cfg)\n",
    "tokenizer = build_tokenizer(cfg)\n",
    "SpecialToken.add_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.pretrain import PretrainDataset\n",
    "\n",
    "\n",
    "data = PretrainDataset(train_data, tokenizer, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.evaluate import EvaluateDataset\n",
    "\n",
    "eval_data = EvaluateDataset(valid_data, tokenizer, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.train.fast_test = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [04:04<00:00,  8.18it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "_d = data\n",
    "for i in tqdm(range(len(_d))):\n",
    "    try:\n",
    "        _d[i]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1163, 1163)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = i % data.data.target_edge_index.shape[1]\n",
    "i, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "triple = (\n",
    "            torch.cat(\n",
    "                [\n",
    "                    data.data.target_edge_index[:, idx],\n",
    "                    data.data.target_edge_type[idx].unsqueeze(0),\n",
    "                ]\n",
    "            )\n",
    "            .t()\n",
    "            .view(-1, 3)\n",
    "        )\n",
    "entities = torch.cat([triple[:, 0], triple[:, 1]]).unique()\n",
    "subg = data.sample_from_edge_index(entities)\n",
    "\n",
    "# 采样子图中要预测的 triples，以及对应的负样本\n",
    "# cfg task num_mask\n",
    "edge_mask = torch.randperm(subg.target_edge_index.shape[1])[:data.cfg.task.num_mask]\n",
    "# mask_triples: tris x 3\n",
    "mask_triples = (\n",
    "    torch.cat(\n",
    "        [\n",
    "            subg.target_edge_index[:, edge_mask],\n",
    "            subg.target_edge_type[edge_mask].unsqueeze(0),\n",
    "        ]\n",
    "    )\n",
    "    .t()\n",
    "    .view(-1, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "_data = data.data\n",
    "batch = mask_triples.view(-1, 3)\n",
    "num_negative = data.cfg.task.num_negative\n",
    "strict = data.cfg.task.strict_negative\n",
    "limit_nodes = subg.n_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.LongTensor{[0, 8]}, size=[8]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# TODO FIXME 为了应对 bs 为1的情况，随机替换 h / t\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _bs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# t_index[0, 1:] = neg_t_index\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m     \u001b[43mh_index\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m neg_h_index\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# if random() > 0.5:\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m#     # 替换 t    (预测 t)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;66;03m#     t_index[0, 1:] = neg_t_index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;66;03m#     h_index[0, 1:] = neg_h_index\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     t_index[:batch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m neg_t_index\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.LongTensor{[0, 8]}, size=[8]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "batch_size = len(batch)\n",
    "_bs = batch_size\n",
    "if _bs == 1:\n",
    "    batch_size = 2\n",
    "\n",
    "\n",
    "pos_h_index, pos_t_index, pos_r_index = batch.t()\n",
    "\n",
    "# strict negative sampling vs random negative sampling\n",
    "if strict:\n",
    "    t_mask, h_mask = tasks.strict_negative_mask(_data, batch)\n",
    "    t_mask = t_mask[:batch_size // 2]\n",
    "    if limit_nodes is not None:\n",
    "        t_mask = t_mask[:, limit_nodes]\n",
    "    neg_t_candidate = t_mask.nonzero()[:, 1]\n",
    "    num_t_candidate = t_mask.sum(dim=-1)\n",
    "    # draw samples for negative tails\n",
    "    rand = torch.rand(len(t_mask), num_negative, device=batch.device)\n",
    "    index = (rand * num_t_candidate.unsqueeze(-1)).long()\n",
    "    index = index + (num_t_candidate.cumsum(0) - num_t_candidate).unsqueeze(-1)\n",
    "    neg_t_index = neg_t_candidate[index]\n",
    "    if limit_nodes is not None:\n",
    "        neg_t_index = limit_nodes[neg_t_index]\n",
    "\n",
    "    h_mask = h_mask[batch_size // 2:]\n",
    "    if limit_nodes is not None:\n",
    "        h_mask = h_mask[:, limit_nodes]\n",
    "    neg_h_candidate = h_mask.nonzero()[:, 1]\n",
    "    num_h_candidate = h_mask.sum(dim=-1)\n",
    "    # draw samples for negative heads\n",
    "    rand = torch.rand(len(h_mask), num_negative, device=batch.device)\n",
    "    index = (rand * num_h_candidate.unsqueeze(-1)).long()\n",
    "    index = index + (num_h_candidate.cumsum(0) - num_h_candidate).unsqueeze(-1)\n",
    "    neg_h_index = neg_h_candidate[index]\n",
    "    if limit_nodes is not None:\n",
    "        neg_h_index = limit_nodes[neg_h_index]\n",
    "else:\n",
    "    neg_index = torch.randint(_data.num_nodes, (batch_size, num_negative), device=batch.device)\n",
    "    neg_t_index, neg_h_index = neg_index[:batch_size // 2], neg_index[batch_size // 2:]\n",
    "\n",
    "h_index = pos_h_index.unsqueeze(-1).repeat(1, num_negative + 1)\n",
    "t_index = pos_t_index.unsqueeze(-1).repeat(1, num_negative + 1)\n",
    "r_index = pos_r_index.unsqueeze(-1).repeat(1, num_negative + 1)\n",
    "\n",
    "# TODO FIXME 为了应对 bs 为1的情况，随机替换 h / t\n",
    "if _bs == 1:\n",
    "    # t_index[0, 1:] = neg_t_index\n",
    "    h_index[0, 1:] = neg_h_index\n",
    "    # if random() > 0.5:\n",
    "    #     # 替换 t    (预测 t)\n",
    "    #     t_index[0, 1:] = neg_t_index\n",
    "    # else:\n",
    "    #     # 替换 h    (预测 h)\n",
    "    #     h_index[0, 1:] = neg_h_index\n",
    "else:\n",
    "    t_index[:batch_size // 2, 1:] = neg_t_index\n",
    "    h_index[batch_size // 2:, 1:] = neg_h_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_h_candidate = torch.tensor([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[True, True, True,  ..., True, True, True]]),\n",
       " torch.Size([1, 1594]),\n",
       " tensor([], size=(0, 2), dtype=torch.bool),\n",
       " tensor([[952, 952, 952, 952, 952, 952, 952, 952]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_1, _2 = tasks.strict_negative_mask(_data, batch)\n",
    "_2, _2.shape, h_mask[batch_size // 2:], neg_t_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[952, 952, 952, 952, 952, 952, 952, 952, 952]]),\n",
       " torch.Size([1, 9]),\n",
       " tensor([], size=(0, 8), dtype=torch.int64),\n",
       " torch.Size([0, 8]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_index, h_index.shape, neg_h_index, neg_h_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra-llm-ALrbjYbK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
