{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "import transformers\n",
    "from transformers import Trainer, TrainingArguments, HfArgumentParser\n",
    "\n",
    "from script.build_model import build_model, build_tokenizer_model, build_tokenizer\n",
    "from src.trainer.metric import ROUGE, metric_fn\n",
    "from src.trainer.trainer import KGLLMTrainer\n",
    "from config.config import Config\n",
    "from src.data.datasets import FB15k237Inductive\n",
    "from src.data.types import CustomData\n",
    "from src.ultra import tasks, util\n",
    "from src.ultra.models import Ultra\n",
    "\n",
    "\n",
    "def parse_args(config_path: str) -> Config:\n",
    "    parser = HfArgumentParser(Config)\n",
    "    cfg: Config = parser.parse_yaml_file(config_path)[0]\n",
    "    cfg.train = cfg.train.set_dataloader(train_batch_size=cfg.train.batch_size, eval_batch_size=cfg.train.batch_size)\n",
    "\n",
    "    # get_logger().\n",
    "    return cfg\n",
    "\n",
    "\n",
    "def get_data(cfg: Config) -> tuple[InMemoryDataset, CustomData, CustomData, CustomData]:\n",
    "    dataset = util.build_dataset(cfg)\n",
    "    return dataset, dataset[0], dataset[1], dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = parse_args(\"config/pretrain/pretrain_0.yaml\")\n",
    "transformers.set_seed(cfg.train.seed)\n",
    "\n",
    "task_name = cfg.task.name\n",
    "\n",
    "# data sampler, loader, collator -> custom trainer\n",
    "dataset, train_data, valid_data, test_data = get_data(cfg=cfg)\n",
    "\n",
    "# tokenizer, model = build_tokenizer_model(cfg)\n",
    "tokenizer = build_tokenizer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.pretrain import PretrainDataset\n",
    "\n",
    "\n",
    "data = PretrainDataset(train_data, tokenizer, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"total len: {len(data)}\")\n",
    "for i in range(len(data)):\n",
    "    try:\n",
    "        data[i]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra-llm-ALrbjYbK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
